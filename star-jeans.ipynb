{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> <b>ETL Building for an E-commerce Jeans Company</b></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"justify\"> Michael, Franklin and Trevor, after several successful businesses, are starting new a company called Star Jeans. For now, their plan is to enter the USA fashion market through an E-commerce. The initial idea is to sell one product for a specific audience, which is <b>male jeans</b>. Their goal is to keep prices low and slowly increase them, as they get new clients. However, this market already has strong competitors, such as H&M for instance. In addition to that, the three businessmen aren't familiar with this segment in particular. Therefore, in order to better understand how this market works they hired a Data Science/Engineering freelancer, to gather information regarding H&M. They want to know the following information about H&M male jeans: </p>\n",
    "\n",
    "- Product Name\n",
    "- Product Type\n",
    "- Product Fit\n",
    "- Product Color\n",
    "- Product Composition\n",
    "- Product Price </p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import psycopg2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from datetime   import datetime\n",
    "from bs4        import BeautifulSoup\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Extraction**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. **Extracting the webpage links for all products (Job 02)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we'll have to gather the web page link for each product in the showroom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html' # h&m url\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'} # user agent\n",
    "page = requests.get(url, headers=headers) # accessing url\n",
    "\n",
    "# BeautifulSoup Object\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this website doesn't show all items in the same page we need to find the maximum page size to gather all products. For this particular instance, it shows **36** items per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paging\n",
    "total_item = soup.find_all('h2', class_='load-more-heading')[0].get('data-total') # total items available\n",
    "\n",
    "page_number = np.round(int(total_item)/ 36) + 1 # rounded necessary page number \n",
    "url_complete = url + '?page-size=' + str(int(page_number*36)) # new url -> now with all items in the same page\n",
    "\n",
    "# New Request\n",
    "url = url_complete # complete h&m url\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'} # user agent\n",
    "page = requests.get(url, headers=headers) # accessing url\n",
    "\n",
    "# New BeautifulSoup Object\n",
    "soup = BeautifulSoup(page.text, 'html.parser') \n",
    "products = soup.find('ul', class_='products-listing small') # finding products full list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's possible to collect the product id for later merging and concating, as well as the product type, since this information isn't available on the individual products links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting\n",
    "product_list = products.find_all('article', class_='hm-product-item') # getting each product\n",
    "\n",
    "# product id\n",
    "product_id = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "# product_type\n",
    "product_type = [p.get('data-category') for p in product_list]\n",
    "\n",
    "# Building the Initial DataFrame\n",
    "data = pd.DataFrame([product_id, product_type]).T\n",
    "data.columns = ['product_id', 'product_type']\n",
    "\n",
    "# initial adjustments\n",
    "data['product_id'] = data['product_id'].astype(str)\n",
    "data['style_id'] = data['product_id'].apply(lambda x: x[:-3])\n",
    "data['color_id'] = data['product_id'].apply(lambda x: x[-3:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each product_id is composed of two id's, they had to be split into:\n",
    "- style_id: Represent the product's style (e.g. Skinny Jeans)\n",
    "- color_id: Represent the product's color, being the last 3 digits of a product_id\n",
    "\n",
    "Therefore, product_id = style_id + color_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. **Extracting other attributes for each product (Job 02)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'} # user agent\n",
    "\n",
    "# Empty Reference DataFrame \n",
    "df_compositions = pd.DataFrame()\n",
    "\n",
    "# API Requests\n",
    "for i in range(len(data)):\n",
    "    url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id'] + '.html'\n",
    "\n",
    "    page = requests.get(url, headers=headers)\n",
    "\n",
    "    # Beautiful Object\n",
    "    soup = BeautifulSoup(page.text, 'html.parser') \n",
    "\n",
    "    ############################################################################################ Extracting Color ########################################################################################\n",
    "    id_color_list = soup.find_all('a', class_='filter-option miniature active') + soup.find_all('a', class_='filter-option miniature')\n",
    "\n",
    "    color_name = [p.get('data-color') for p in id_color_list] # getting the color\n",
    "    product_id = [p.get('data-articlecode') for p in id_color_list] # getting the ID - each color has a individual ID (last 3 digits)\n",
    "\n",
    "    df_color = pd.DataFrame([product_id, color_name]).T\n",
    "    df_color.columns = ['product_id', 'color_name']\n",
    "\n",
    "    for j in range(len(df_color)):\n",
    "        ####################################### API Requests #######################################\n",
    "        url = 'https://www2.hm.com/en_us/productpage.' + df_color.loc[j, 'product_id'] + '.html'\n",
    "        page = requests.get(url, headers=headers)    \n",
    "        soup = BeautifulSoup(page.text, 'html.parser') # Beautiful Object\n",
    "        \n",
    "        ####################################### Product Name #######################################\n",
    "        product_name = soup.find_all('hm-product-name', id='js-product-name')\n",
    "        product_name = product_name[0].get_text().strip()\n",
    "        \n",
    "        product_price = soup.find_all('div', class_='price parbase')\n",
    "        product_price = product_price[0].get_text().strip()\n",
    "\n",
    "        ######################################################################################## Extracting Fit and Composition #############################################################################\n",
    "        product_composition_list = soup.find_all('div', class_='details-attributes-list-item') # attributes list\n",
    "        product_composition = [list(filter(None, item.get_text().split('\\n'))) for item in product_composition_list]\n",
    "        \n",
    "        if product_composition != []: # if not empty\n",
    "            df_composition_ref = pd.DataFrame(product_composition).T # creating Dataframe from product_composition list\n",
    "            df_composition_ref.columns = df_composition_ref.iloc[0, :] # sets the first row as columns\n",
    "            df_composition = df_composition_ref[['Fit', 'Composition', 'Art. No.']] # selecting only necessary columns\n",
    "            df_composition = df_composition[df_composition['Composition'].notnull()]\n",
    "            df_composition = df_composition.iloc[1:].fillna(method='ffill') # dealing with NaN's\n",
    "\n",
    "            # Replacing Shell\n",
    "            df_composition['Composition'] = df_composition['Composition'].replace('Shell: ', '', regex=True)\n",
    "\n",
    "            # Renaming columns\n",
    "            df_composition = df_composition.rename(columns = {'Fit' : 'fit', 'Composition' : 'composition', 'Art. No.' : 'product_id'})\n",
    "\n",
    "            # Adding product_name and product_price\n",
    "            df_composition['product_name'] = product_name\n",
    "            df_composition['product_price'] = product_price\n",
    "            ######################################################################################## Merging #####################################################################################################\n",
    "            # Color + Composition\n",
    "            df_composition = pd.merge(df_composition, df_color, how='left', on='product_id')\n",
    "\n",
    "            # Attributes\n",
    "            df_compositions = pd.concat([df_compositions, df_composition], axis=0)\n",
    "        \n",
    "        else: # if empty\n",
    "            None\n",
    "\n",
    "# Generate Style ID + Color ID\n",
    "df_compositions['style_id'] = df_compositions['product_id'].apply(lambda x: x[:-3]) # product_id = style_id + color_id\n",
    "df_compositions['color_id'] = df_compositions['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "# scraping datetime\n",
    "df_compositions['scraping_datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')        \n",
    "\n",
    "# Merging\n",
    "df_raw = pd.merge(data[['product_type', 'style_id']], df_compositions, how='left', on='style_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. **Merging product_type and df_compositions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.merge(data[['product_type', 'style_id']], df_compositions, how='left', on='style_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. **Cleaning Data (Job 03)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>style_id</th>\n",
       "      <th>fit</th>\n",
       "      <th>composition</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>color_name</th>\n",
       "      <th>color_id</th>\n",
       "      <th>scraping_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>1024256</td>\n",
       "      <td>Slim fit</td>\n",
       "      <td>Cotton 99%, Spandex 1%</td>\n",
       "      <td>1024256001</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>Black</td>\n",
       "      <td>001</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>1024256</td>\n",
       "      <td>Slim fit</td>\n",
       "      <td>Pocket lining: Polyester 65%, Cotton 35%</td>\n",
       "      <td>1024256001</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>Black</td>\n",
       "      <td>001</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>1024256</td>\n",
       "      <td>Slim fit</td>\n",
       "      <td>Cotton 99%, Spandex 1%</td>\n",
       "      <td>1024256002</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>Light denim blue</td>\n",
       "      <td>002</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>1024256</td>\n",
       "      <td>Slim fit</td>\n",
       "      <td>Pocket lining: Polyester 65%, Cotton 35%</td>\n",
       "      <td>1024256002</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>Light denim blue</td>\n",
       "      <td>002</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>1024256</td>\n",
       "      <td>Slim fit</td>\n",
       "      <td>Cotton 99%, Spandex 1%</td>\n",
       "      <td>1024256003</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>Light denim blue</td>\n",
       "      <td>003</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8817</th>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>0985197</td>\n",
       "      <td>Slim fit</td>\n",
       "      <td>Pocket lining: Polyester 65%, Cotton 35%</td>\n",
       "      <td>0985197005</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$15.99</td>\n",
       "      <td>Dark denim blue</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8818</th>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>0985197</td>\n",
       "      <td>Slim fit</td>\n",
       "      <td>Cotton 99%, Spandex 1%</td>\n",
       "      <td>0985197006</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>Light denim blue</td>\n",
       "      <td>006</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8819</th>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>0985197</td>\n",
       "      <td>Slim fit</td>\n",
       "      <td>Pocket lining: Polyester 65%, Cotton 35%</td>\n",
       "      <td>0985197006</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>Light denim blue</td>\n",
       "      <td>006</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8820</th>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>0985197</td>\n",
       "      <td>Slim fit</td>\n",
       "      <td>Cotton 99%, Spandex 1%</td>\n",
       "      <td>0985197007</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>Dark gray</td>\n",
       "      <td>007</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821</th>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>0985197</td>\n",
       "      <td>Slim fit</td>\n",
       "      <td>Pocket lining: Polyester 65%, Cotton 35%</td>\n",
       "      <td>0985197007</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$19.99</td>\n",
       "      <td>Dark gray</td>\n",
       "      <td>007</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8822 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_type style_id       fit  \\\n",
       "0     men_jeans_slim  1024256  Slim fit   \n",
       "1     men_jeans_slim  1024256  Slim fit   \n",
       "2     men_jeans_slim  1024256  Slim fit   \n",
       "3     men_jeans_slim  1024256  Slim fit   \n",
       "4     men_jeans_slim  1024256  Slim fit   \n",
       "...              ...      ...       ...   \n",
       "8817  men_jeans_slim  0985197  Slim fit   \n",
       "8818  men_jeans_slim  0985197  Slim fit   \n",
       "8819  men_jeans_slim  0985197  Slim fit   \n",
       "8820  men_jeans_slim  0985197  Slim fit   \n",
       "8821  men_jeans_slim  0985197  Slim fit   \n",
       "\n",
       "                                   composition  product_id product_name  \\\n",
       "0                       Cotton 99%, Spandex 1%  1024256001   Slim Jeans   \n",
       "1     Pocket lining: Polyester 65%, Cotton 35%  1024256001   Slim Jeans   \n",
       "2                       Cotton 99%, Spandex 1%  1024256002   Slim Jeans   \n",
       "3     Pocket lining: Polyester 65%, Cotton 35%  1024256002   Slim Jeans   \n",
       "4                       Cotton 99%, Spandex 1%  1024256003   Slim Jeans   \n",
       "...                                        ...         ...          ...   \n",
       "8817  Pocket lining: Polyester 65%, Cotton 35%  0985197005   Slim Jeans   \n",
       "8818                    Cotton 99%, Spandex 1%  0985197006   Slim Jeans   \n",
       "8819  Pocket lining: Polyester 65%, Cotton 35%  0985197006   Slim Jeans   \n",
       "8820                    Cotton 99%, Spandex 1%  0985197007   Slim Jeans   \n",
       "8821  Pocket lining: Polyester 65%, Cotton 35%  0985197007   Slim Jeans   \n",
       "\n",
       "     product_price        color_name color_id    scraping_datetime  \n",
       "0           $19.99             Black      001  2022-12-21 20:53:03  \n",
       "1           $19.99             Black      001  2022-12-21 20:53:03  \n",
       "2           $19.99  Light denim blue      002  2022-12-21 20:53:03  \n",
       "3           $19.99  Light denim blue      002  2022-12-21 20:53:03  \n",
       "4           $19.99  Light denim blue      003  2022-12-21 20:53:03  \n",
       "...            ...               ...      ...                  ...  \n",
       "8817        $15.99   Dark denim blue      005  2022-12-21 20:53:03  \n",
       "8818        $19.99  Light denim blue      006  2022-12-21 20:53:03  \n",
       "8819        $19.99  Light denim blue      006  2022-12-21 20:53:03  \n",
       "8820        $19.99         Dark gray      007  2022-12-21 20:53:03  \n",
       "8821        $19.99         Dark gray      007  2022-12-21 20:53:03  \n",
       "\n",
       "[8822 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_type         object\n",
      "style_id             object\n",
      "fit                  object\n",
      "composition          object\n",
      "product_id           object\n",
      "product_name         object\n",
      "product_price        object\n",
      "color_name           object\n",
      "color_id             object\n",
      "scraping_datetime    object\n",
      "dtype: object\n",
      "\n",
      "product_type         0\n",
      "style_id             0\n",
      "fit                  0\n",
      "composition          0\n",
      "product_id           0\n",
      "product_name         0\n",
      "product_price        0\n",
      "color_name           0\n",
      "color_id             0\n",
      "scraping_datetime    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_raw.dtypes)\n",
    "print()\n",
    "print(df_raw.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. **Individual Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.rename(columns = {'fit' : 'product_fit', 'color_name' : 'product_color', 'composition' : 'product_composition'}, inplace=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.1. **product_color**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['product_color'] = df_raw['product_color'].apply(lambda x: x.replace(' ', '_').lower() if pd.notnull(x) else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.2. **product_fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['product_fit'] = df_raw['product_fit'].apply(lambda x: x.replace(' ', '_').lower() if pd.notnull(x) else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.3. **product_name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['product_name'] = df_raw['product_name'].apply(lambda x: x.replace(' ', '_').lower() if pd.notnull(x) else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.4. **product_price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['product_price'] = df_raw['product_price'].apply(lambda x: x.replace('$', ' ') if pd.notnull(x) else x)\n",
    "df_raw['product_price'] = pd.to_numeric(df_raw['product_price'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.5. **scraping_datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['scraping_datetime'] = pd.to_datetime(df_raw['scraping_datetime'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.6. **product_composition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw[~df_raw['product_composition'].str.contains('Pocket lining', na=False)] # removing all lines that contain Pocket lining\n",
    "df_raw = df_raw[~df_raw['product_composition'].str.contains('Lining', na=False)] # removing all lines that contain Lining\n",
    "df_raw = df_raw[~df_raw['product_composition'].str.contains('Pocket', na=False)].reset_index().drop(columns=['index']) # removing all lines that Pocket\n",
    "\n",
    "df_aux = df_raw['product_composition'].str.split(',', expand=True) # auxiliary column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clients aren't interested in Pocket information. Hence the removal above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cotton 98%     2181\n",
       "Cotton 99%     1768\n",
       "Cotton 100%     905\n",
       "Cotton 90%      180\n",
       "Cotton 89%      108\n",
       "Cotton 77%       66\n",
       "Cotton 78%       57\n",
       "Cotton 79%       41\n",
       "Cotton 80%       25\n",
       "Rayon 50%         2\n",
       "Lyocell 55%       2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Spandex 2%             2181\n",
       " Spandex 1%             1768\n",
       " Elastomultiester 8%     180\n",
       " Polyester 21%           123\n",
       " Elastomultiester 9%     108\n",
       " Polyester 19%            41\n",
       " Polyester 20%            25\n",
       " Lyocell 50%               2\n",
       " Cotton 30%                2\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Spandex 2%    370\n",
       " Spandex 1%    107\n",
       " Rayon 15%       2\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux[2].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can recover each composition and put it on the correct column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cotton\n",
    "df_aux['cotton'] = np.where(df_aux[0].str.contains('Cotton'), df_aux[0], np.nan) # puts the cotton values on 'cotton' column if df1' first column contains 'Cotton', else puts NaN's\n",
    "df_aux['cotton'] = np.where(df_aux[1].str.contains('Cotton'), df_aux[1], df_aux['cotton']) # there're some cotton values on the second column \n",
    "\n",
    "#  Spandex\n",
    "df_aux['spandex'] = np.where(df_aux[1].str.contains('Spandex'), df_aux[1], np.nan) # puts the spandex values on 'spandex' column if df1' second column contains 'Spandex', else puts NaN's\n",
    "df_aux['spandex'] = np.where(df_aux[2].str.contains('Spandex'), df_aux[2], df_aux['spandex']) # there're some spandex values on the third column\n",
    "\n",
    "# Polyester\n",
    "df_aux['polyester'] = np.where(df_aux[1].str.contains('Polyester'), df_aux[1], np.nan) # puts the polyester values on 'polyester' column if df1' second column contains 'Polyester', else puts NaN's\n",
    "\n",
    "# Elastomultiester \n",
    "df_aux['elastomultiester'] = np.where(df_aux[1].str.contains('Elastomultiester'), df_aux[1], np.nan) # puts the elastomultiester values on 'elastomultiester' column if df1' second column contains 'Elastomultiester', else puts NaN's\n",
    "\n",
    "# Lyocell\n",
    "df_aux['lyocell'] = np.where(df_aux[0].str.contains('Lyocell'), df_aux[0], np.nan) # puts the lyocell values on 'lyocell' column if df1' first column contains 'Lyocell', else puts NaN's\n",
    "df_aux['lyocell'] = np.where(df_aux[1].str.contains('Lyocell'), df_aux[1], df_aux['lyocell']) # there're some lyocell values on the second column\n",
    "\n",
    "# Rayon\n",
    "df_aux['rayon'] = np.where(df_aux[0].str.contains('Rayon'), df_aux[0], np.nan) # puts the rayon values on 'rayon' column if df1' first column contains 'rayon', else puts NaN's\n",
    "df_aux['rayon'] = np.where(df_aux[2].str.contains('Rayon'), df_aux[2], df_aux['rayon']) # there're some spandex values on the third column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "df_aux = df_aux.drop(columns=[0, 1, 2]) # dropping auxiliary columns\n",
    "df_raw = pd.concat([df_raw, df_aux], axis=1) # concat df_aux and df_raw\n",
    "df_raw = df_raw.drop(columns=['product_composition']) # dropping product_composition column\n",
    "\n",
    "# Extracting only the actual numbers\n",
    "df_raw['cotton'] = df_raw['cotton'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else 0) \n",
    "df_raw['spandex'] = df_raw['spandex'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else 0)\n",
    "df_raw['polyester'] = df_raw['polyester'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else 0) \n",
    "df_raw['elastomultiester'] = df_raw['elastomultiester'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else 0) \n",
    "df_raw['lyocell'] = df_raw['lyocell'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else 0) \n",
    "df_raw['rayon'] = df_raw['rayon'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else 0) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. **Final Adjustments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>style_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_fit</th>\n",
       "      <th>product_color</th>\n",
       "      <th>cotton</th>\n",
       "      <th>spandex</th>\n",
       "      <th>polyester</th>\n",
       "      <th>elastomultiester</th>\n",
       "      <th>lyocell</th>\n",
       "      <th>rayon</th>\n",
       "      <th>product_price</th>\n",
       "      <th>scraping_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>1024256</td>\n",
       "      <td>001</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>black</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.99</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1024256002</td>\n",
       "      <td>1024256</td>\n",
       "      <td>002</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>light_denim_blue</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.99</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024256003</td>\n",
       "      <td>1024256</td>\n",
       "      <td>003</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>light_denim_blue</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.99</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024256004</td>\n",
       "      <td>1024256</td>\n",
       "      <td>004</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>denim_blue</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.99</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1024256005</td>\n",
       "      <td>1024256</td>\n",
       "      <td>005</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>dark_blue</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.99</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5052</th>\n",
       "      <td>0985197005</td>\n",
       "      <td>0985197</td>\n",
       "      <td>005</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>dark_denim_blue</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.99</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>0985197007</td>\n",
       "      <td>0985197</td>\n",
       "      <td>007</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>slim_fit</td>\n",
       "      <td>dark_gray</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.99</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>1051644001</td>\n",
       "      <td>1051644</td>\n",
       "      <td>001</td>\n",
       "      <td>loose_jeans</td>\n",
       "      <td>men_jeans_loose</td>\n",
       "      <td>loose_fit</td>\n",
       "      <td>denim_blue</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.15</td>\n",
       "      <td>44.99</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>1025726003</td>\n",
       "      <td>1025726</td>\n",
       "      <td>003</td>\n",
       "      <td>relaxed_jeans</td>\n",
       "      <td>men_jeans_relaxed</td>\n",
       "      <td>relaxed_fit</td>\n",
       "      <td>graphite_gray</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.99</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>1025726002</td>\n",
       "      <td>1025726</td>\n",
       "      <td>002</td>\n",
       "      <td>relaxed_jeans</td>\n",
       "      <td>men_jeans_relaxed</td>\n",
       "      <td>relaxed_fit</td>\n",
       "      <td>light_denim_blue</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.99</td>\n",
       "      <td>2022-12-21 20:53:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id style_id color_id   product_name       product_type  \\\n",
       "0     1024256001  1024256      001     slim_jeans     men_jeans_slim   \n",
       "1     1024256002  1024256      002     slim_jeans     men_jeans_slim   \n",
       "2     1024256003  1024256      003     slim_jeans     men_jeans_slim   \n",
       "3     1024256004  1024256      004     slim_jeans     men_jeans_slim   \n",
       "4     1024256005  1024256      005     slim_jeans     men_jeans_slim   \n",
       "...          ...      ...      ...            ...                ...   \n",
       "5052  0985197005  0985197      005     slim_jeans     men_jeans_slim   \n",
       "5053  0985197007  0985197      007     slim_jeans     men_jeans_slim   \n",
       "5089  1051644001  1051644      001    loose_jeans    men_jeans_loose   \n",
       "5297  1025726003  1025726      003  relaxed_jeans  men_jeans_relaxed   \n",
       "5298  1025726002  1025726      002  relaxed_jeans  men_jeans_relaxed   \n",
       "\n",
       "      product_fit     product_color  cotton  spandex  polyester  \\\n",
       "0        slim_fit             black    0.99     0.01        0.0   \n",
       "1        slim_fit  light_denim_blue    0.99     0.01        0.0   \n",
       "2        slim_fit  light_denim_blue    0.99     0.01        0.0   \n",
       "3        slim_fit        denim_blue    0.99     0.01        0.0   \n",
       "4        slim_fit         dark_blue    0.99     0.01        0.0   \n",
       "...           ...               ...     ...      ...        ...   \n",
       "5052     slim_fit   dark_denim_blue    0.99     0.01        0.0   \n",
       "5053     slim_fit         dark_gray    0.99     0.01        0.0   \n",
       "5089    loose_fit        denim_blue    0.30     0.00        0.0   \n",
       "5297  relaxed_fit     graphite_gray    1.00     0.00        0.0   \n",
       "5298  relaxed_fit  light_denim_blue    1.00     0.00        0.0   \n",
       "\n",
       "      elastomultiester  lyocell  rayon  product_price   scraping_datetime  \n",
       "0                  0.0     0.00   0.00          19.99 2022-12-21 20:53:03  \n",
       "1                  0.0     0.00   0.00          19.99 2022-12-21 20:53:03  \n",
       "2                  0.0     0.00   0.00          19.99 2022-12-21 20:53:03  \n",
       "3                  0.0     0.00   0.00          19.99 2022-12-21 20:53:03  \n",
       "4                  0.0     0.00   0.00          19.99 2022-12-21 20:53:03  \n",
       "...                ...      ...    ...            ...                 ...  \n",
       "5052               0.0     0.00   0.00          15.99 2022-12-21 20:53:03  \n",
       "5053               0.0     0.00   0.00          19.99 2022-12-21 20:53:03  \n",
       "5089               0.0     0.55   0.15          44.99 2022-12-21 20:53:03  \n",
       "5297               0.0     0.00   0.00          39.99 2022-12-21 20:53:03  \n",
       "5298               0.0     0.00   0.00          11.99 2022-12-21 20:53:03  \n",
       "\n",
       "[179 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.drop_duplicates().copy() # dropping duplicates\n",
    "\n",
    "df = df[['product_id', 'style_id', 'color_id', 'product_name', 'product_type', \n",
    "         'product_fit', 'product_color',  'cotton', 'spandex', 'polyester', \n",
    "         'elastomultiester', 'lyocell', 'rayon', 'product_price', 'scraping_datetime']] # rearranging columns\n",
    "\n",
    "df # final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id                   object\n",
      "style_id                     object\n",
      "color_id                     object\n",
      "product_name                 object\n",
      "product_type                 object\n",
      "product_fit                  object\n",
      "product_color                object\n",
      "cotton                      float64\n",
      "spandex                     float64\n",
      "polyester                   float64\n",
      "elastomultiester            float64\n",
      "lyocell                     float64\n",
      "rayon                       float64\n",
      "product_price               float64\n",
      "scraping_datetime    datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "product_id           0\n",
      "style_id             0\n",
      "color_id             0\n",
      "product_name         0\n",
      "product_type         0\n",
      "product_fit          0\n",
      "product_color        0\n",
      "cotton               0\n",
      "spandex              0\n",
      "polyester            0\n",
      "elastomultiester     0\n",
      "lyocell              0\n",
      "rayon                0\n",
      "product_price        0\n",
      "scraping_datetime    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print()\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final table definition is as follows: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Column**          | **Definition** |\n",
    "|:--------------------:|----------------|\n",
    "|      product_id     | A 10-digit number uniquely assigned to each product, composed of style_id and color_id |\n",
    "|      style_id       | A 7-digit number uniquely assigned to each product style| \n",
    "|      color_id       | A 3-digit number assigned to each product color|\n",
    "|      product_name   | Product's name |\n",
    "|      product_type   | Product's type |\n",
    "|      product_color  | Product's color |\n",
    "|      product_fit    | Product's fit - if it's slim, skinny, loose, etc |\n",
    "|      cotton         | Percentage of cotton in the product's composition |\n",
    "|      spandex        | Percentage of spandex in the product's composition |\n",
    "|      polyester      | Percentage of polyester in the product's composition |\n",
    "|    elastomultiester | Percentage of elastomultiester in the product's composition |\n",
    "|       lyocell       | Percentage of lyocell in the product's composition |\n",
    "|       rayon         | Percentage of rayon in the product's composition |\n",
    "|       product_price | Product's unit price |\n",
    "|  scraping_datetime  | The Date of which the data scraping was performed |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. **Saving to Database (Job 04)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL HAD TO BE RAN ONLY ONCE, TO ADD THE TABLE IN THE DATABASE.\n",
    "# establish connections\n",
    "# conn_string = 'postgresql://brunodifranco:ExoCs9IRXJ6u@ep-soft-disk-362766.us-east-2.aws.neon.tech:5432/neondb'\n",
    "\n",
    "# db = create_engine(conn_string)\n",
    "# conn = db.connect()\n",
    "# conn1 = psycopg2.connect(\n",
    "# database=\"neondb\",\n",
    "# user='brunodifranco',\n",
    "# password='ExoCs9IRXJ6u',\n",
    "# host='ep-soft-disk-362766.us-east-2.aws.neon.tech',\n",
    "# port= '5432'\n",
    "# )\n",
    "\n",
    "# conn1.autocommit = True\n",
    "# cursor = conn1.cursor()\n",
    "\n",
    "# query_hm = \"\"\"\n",
    "#     CREATE TABLE hm (\n",
    "#         product_id TEXT,\n",
    "#         style_id TEXT,\n",
    "#         color_id TEXT,\n",
    "#         product_name TEXT,\n",
    "#         product_type TEXT,\n",
    "#         product_color TEXT,\n",
    "#         product_fit TEXT,\n",
    "#         cotton REAL,\n",
    "#         spandex REAL,\n",
    "#         polyester REAL,\n",
    "#         elastomultiester REAL,\n",
    "#         lyocell REAL,\n",
    "#         rayon REAL,\n",
    "#         product_price REAL,\n",
    "#         scraping_datetime TEXT\n",
    "#     )\n",
    "# \"\"\"\n",
    "# cursor.execute(query_hm)\n",
    "\n",
    "# conn1.commit()\n",
    "# conn1.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every new data that comes in is added in the database by these following lines (of course not via this notebook, but via the python scheduled script):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_insert = df.copy()\n",
    "conn = create_engine('postgresql://brunodifranco:ExoCs9IRXJ6u@ep-soft-disk-362766.us-east-2.aws.neon.tech:5432/neondb', echo=False)\n",
    "df_insert.to_sql('hm', con=conn, if_exists='append', index=False) # Inserting data to table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed3943dba37f3ed717092a780584c496f36863d6c99891baccd6632ecc02cdda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
